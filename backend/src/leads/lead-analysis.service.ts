import { Injectable, Logger } from '@nestjs/common';
import { PrismaService } from '../prisma/prisma.service';
import OpenAI from 'openai';

@Injectable()
export class LeadAnalysisService {
  private readonly logger = new Logger(LeadAnalysisService.name);
  private openai: OpenAI | null = null;

  constructor(private prisma: PrismaService) {
    const apiKey = process.env.OPENAI_API_KEY;
    if (apiKey && apiKey !== 'sk-xxxxx' && apiKey.length > 20) {
      this.openai = new OpenAI({ apiKey });
      this.logger.log('‚úÖ OpenAI initialized for lead analysis (GPT-4o-mini)');
      this.logger.log('üß† AI will classify leads, score them, and generate personalized messages');
    } else {
      this.logger.warn('‚ö†Ô∏è OPENAI_API_KEY not set or invalid, using mock classification');
      this.logger.warn('‚ö†Ô∏è To enable AI features, set OPENAI_API_KEY in .env file');
    }
  }

  /**
   * Analyse un Lead pour d√©terminer sa qualification et sugg√©rer un message
   * Appel√© par un Cron Job ou une Queue
   */
  async analyzePendingLeads(workspaceId: string) {
    // R√©cup√©rer les leads "new" qui n'ont pas encore √©t√© analys√©s (pas de leadType)
    const leads = await this.prisma.lead.findMany({
      where: {
        workspaceId,
        status: 'new',
        leadType: null, // Pas encore classifi√©
        // On prend ceux qui ont au moins une interaction
        lastInteractionAt: { not: null },
      },
      take: 10, // Traitement par lots
      include: {
        target: {
            include: {
                interactions: {
                    take: 5, // Prendre les 5 derni√®res interactions pour le contexte
                    orderBy: { createdAt: 'desc' }
                }
            }
        }
      }
    });

    if (leads.length > 0) {
      this.logger.log(`\n${'='.repeat(80)}`);
      this.logger.log(`ü§ñ [FlowIA] D√©marrage de l'analyse IA de ${leads.length} leads...`);
      this.logger.log(`${'='.repeat(80)}\n`);
    }

    for (const lead of leads) {
      await this.analyzeLead(lead);
    }
    
    if (leads.length > 0) {
      this.logger.log(`\n${'='.repeat(80)}`);
      this.logger.log(`‚úÖ [FlowIA] Analyse termin√©e : ${leads.length} leads analys√©s par l'IA`);
      this.logger.log(`${'='.repeat(80)}\n`);
    }
  }

  private async analyzeLead(lead: any) {
    try {
      // Appel OpenAI r√©el ou mock selon disponibilit√©
      const classification = this.openai
        ? await this.realAIClassification(lead)
        : this.mockAIClassification(lead);
      
      // 1. Mettre √† jour la classification du Lead
      await this.prisma.lead.update({
        where: { id: lead.id },
        data: {
          leadType: classification.type,
          interestScore: classification.score, // Score affin√© par l'IA
          notes: classification.reasoning,
        }
      });

      // 2. Cr√©er une suggestion de message
      if (classification.score > 50) { // Uniquement si le lead est int√©ressant
        await this.prisma.suggestedMessage.create({
          data: {
            workspaceId: lead.workspaceId,
            leadId: lead.id,
            content: classification.suggestedMessage,
            status: 'pending',
          }
        });
        this.logger.log(`‚ú® [FlowIA] Message g√©n√©r√© pour @${lead.username} (${classification.type}, score: ${classification.score})`);
        this.logger.log(`   üí¨ Message: "${classification.suggestedMessage}"`);
      } else {
        this.logger.log(`‚ö†Ô∏è [FlowIA] Lead @${lead.username} ignor√© (score trop bas: ${classification.score}/100)`);
      }

    } catch (error) {
      this.logger.error(`‚ùå [FlowIA] Erreur lors de l'analyse du lead ${lead.id}:`, error);
    }
  }

  /**
   * Classification r√©elle via OpenAI
   */
  private async realAIClassification(lead: any): Promise<{
    type: string;
    score: number;
    reasoning: string;
    suggestedMessage: string;
  }> {
    if (!this.openai) {
      return this.mockAIClassification(lead);
    }

    const interactions = lead.target?.interactions || [];
    const interactionsSummary = interactions
      .slice(0, 10)
      .map((i: any) => `- ${i.type}: ${i.message || 'sans message'}`)
      .join('\n');

    const prompt = `Tu es un expert en qualification de leads pour FlowIA, un SaaS de gestion de leads sur les r√©seaux sociaux.

üéØ T√ÇCHE : Analyser ce lead TikTok et le qualifier intelligemment.

üìä CONTEXTE :
- Username : @${lead.username}
- Score d'int√©r√™t actuel : ${lead.interestScore || 0}/100
- Interactions r√©centes :
${interactionsSummary || 'Aucune interaction r√©cente'}

üè∑Ô∏è CAT√âGORIES POSSIBLES :
- "artist" : Artiste, musicien, cr√©ateur de contenu (profil cr√©atif, vid√©os musicales)
- "beatmaker" : Producteur musical, beatmaker (profil production, beats)
- "client_potentiel" : Client potentiel int√©ress√© par les services (questions, demandes)
- "fan_engaged" : Fan tr√®s engag√© (commentaires fr√©quents, partages)
- "passive_observer" : Observateur passif (juste likes/follows)
- "other" : Autre (ne correspond √† aucune cat√©gorie)

üìù ANALYSE √Ä FAIRE :
1. Analyser les interactions pour comprendre le profil
2. D√©terminer le niveau d'engagement r√©el
3. Identifier les signaux d'int√©r√™t (commentaires, questions, partages)
4. Calculer un score d'int√©r√™t pr√©cis (0-100)
5. G√©n√©rer un message personnalis√© et engageant

üí¨ LE MESSAGE DOIT :
- √ätre naturel et conversationnel
- Mentionner quelque chose de sp√©cifique √† ce lead
- √ätre court (max 200 caract√®res)
- Inviter √† la conversation
- En fran√ßais

R√©ponds UNIQUEMENT avec un JSON valide au format suivant :
{
  "type": "cat√©gorie",
  "score": nombre entre 0 et 100,
  "reasoning": "explication courte en fran√ßais de pourquoi cette classification",
  "suggestedMessage": "message personnalis√© court et engageant en fran√ßais (max 200 caract√®res)"
}`;

    // üß† AFFICHER CE QUE L'IA VA ANALYSER
    this.logger.log(`\n${'='.repeat(80)}`);
    this.logger.log(`üß† [IA THINKING] Analyse du lead @${lead.username}`);
    this.logger.log(`${'='.repeat(80)}`);
    this.logger.log(`üìä [IA THINKING] Contexte envoy√© √† l'IA :`);
    this.logger.log(`   - Username: @${lead.username}`);
    this.logger.log(`   - Score actuel: ${lead.interestScore || 0}/100`);
    this.logger.log(`   - Interactions: ${interactions.length} trouv√©es`);
    if (interactionsSummary) {
      this.logger.log(`   - D√©tails des interactions:`);
      interactionsSummary.split('\n').forEach(line => {
        if (line.trim()) this.logger.log(`     ${line}`);
      });
    }
    this.logger.log(`\nüí≠ [IA THINKING] Envoi du prompt √† GPT-4o-mini...`);

    try {
      const completion = await this.openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: 'Tu es un expert en qualification de leads pour les r√©seaux sociaux. Tu analyses les profils TikTok pour identifier les meilleurs prospects. R√©ponds UNIQUEMENT avec du JSON valide, sans markdown, sans code blocks.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: 0.8, // Un peu plus cr√©atif pour les messages
        max_tokens: 600, // Plus d'espace pour des messages plus personnalis√©s
      });

      const response = completion.choices[0]?.message?.content || '{}';
      
      // üß† AFFICHER LA R√âPONSE BRUTE DE L'IA
      this.logger.log(`\nüì• [IA THINKING] R√©ponse brute de l'IA (GPT-4o-mini) :`);
      this.logger.log(`   ${response.substring(0, 500)}${response.length > 500 ? '...' : ''}`);
      
      // Nettoyer la r√©ponse (enlever markdown si pr√©sent)
      let cleanedResponse = response.trim();
      if (cleanedResponse.startsWith('```json')) {
        cleanedResponse = cleanedResponse.replace(/```json\n?/g, '').replace(/```\n?/g, '');
      } else if (cleanedResponse.startsWith('```')) {
        cleanedResponse = cleanedResponse.replace(/```\n?/g, '');
      }
      
      const parsed = JSON.parse(cleanedResponse);
      
      // üß† AFFICHER LE RAISONNEMENT DE L'IA
      this.logger.log(`\nüéØ [IA THINKING] D√©cision de l'IA :`);
      this.logger.log(`   ‚úÖ Cat√©gorie choisie: "${parsed.type}"`);
      this.logger.log(`   üìä Score calcul√©: ${parsed.score}/100`);
      this.logger.log(`   üí≠ Raisonnement: ${parsed.reasoning || 'Aucun raisonnement fourni'}`);
      this.logger.log(`   üí¨ Message g√©n√©r√©: "${parsed.suggestedMessage || 'Aucun message'}"`);
      this.logger.log(`${'='.repeat(80)}\n`);

      return {
        type: parsed.type || 'other',
        score: Math.min(100, Math.max(0, parsed.score || 50)),
        reasoning: parsed.reasoning || 'Analyse effectu√©e par IA',
        suggestedMessage: parsed.suggestedMessage || `Salut @${lead.username} ! Merci pour ton int√©r√™t.`,
      };
    } catch (error) {
      this.logger.error(`Error calling OpenAI for lead ${lead.id}:`, error);
      return this.mockAIClassification(lead);
    }
  }

  // Mock pour simuler l'IA en attendant la cl√© API
  private mockAIClassification(lead: any) {
    const interactions = lead.target?.interactions || [];
    const hasComments = interactions.some((i: any) => i.type === 'comment');
    
    if (hasComments) {
      return {
        type: 'fan_engaged',
        score: 85,
        reasoning: 'A comment√© r√©cemment, engagement fort.',
        suggestedMessage: `Salut @${lead.username} ! Merci pour ton commentaire, √ßa fait plaisir de voir que tu suis le projet. Tu fais quoi dans la vie ?`
      };
    }

    return {
      type: 'passive_observer',
      score: 40,
      reasoning: 'Juste des likes/follows, engagement moyen.',
      suggestedMessage: `Hello @${lead.username}, merci pour le follow ! H√©site pas si tu as des questions sur mon contenu.`
    };
  }
}

